{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-03T18:46:07.063846Z","iopub.status.busy":"2023-12-03T18:46:07.063426Z","iopub.status.idle":"2023-12-03T18:46:07.070584Z","shell.execute_reply":"2023-12-03T18:46:07.069572Z","shell.execute_reply.started":"2023-12-03T18:46:07.063809Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sushovan/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import pytorch_lightning as pl \n","import pandas as pd\n","import os\n","import numpy as np\n","import torch.nn as nn\n","from transformers import BertTokenizer\n","from torch.nn.utils.rnn import pad_sequence\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning import seed_everything\n","from torch.utils.data import random_split\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.539803Z","iopub.status.busy":"2023-12-03T19:01:29.538724Z","iopub.status.idle":"2023-12-03T19:01:29.603459Z","shell.execute_reply":"2023-12-03T19:01:29.602547Z","shell.execute_reply.started":"2023-12-03T19:01:29.539764Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url</th>\n","      <th>title</th>\n","      <th>subtitle</th>\n","      <th>image</th>\n","      <th>claps</th>\n","      <th>responses</th>\n","      <th>reading_time</th>\n","      <th>publication</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n","      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n","      <td>NaN</td>\n","      <td>1.png</td>\n","      <td>850</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n","      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n","      <td>NaN</td>\n","      <td>2.png</td>\n","      <td>1100</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n","      <td>How to Use ggplot2 in Python</td>\n","      <td>A Grammar of Graphics for Python</td>\n","      <td>3.png</td>\n","      <td>767</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>https://towardsdatascience.com/databricks-how-...</td>\n","      <td>Databricks: How to Save Files in CSV on Your L...</td>\n","      <td>When I work on Python projects dealing…</td>\n","      <td>4.jpeg</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n","      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n","      <td>One example of building neural…</td>\n","      <td>5.jpeg</td>\n","      <td>211</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                                url  \\\n","0   1  https://towardsdatascience.com/a-beginners-gui...   \n","1   2  https://towardsdatascience.com/hands-on-graph-...   \n","2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n","3   4  https://towardsdatascience.com/databricks-how-...   \n","4   5  https://towardsdatascience.com/a-step-by-step-...   \n","\n","                                               title  \\\n","0  A Beginner’s Guide to Word Embedding with Gens...   \n","1  Hands-on Graph Neural Networks with PyTorch & ...   \n","2                       How to Use ggplot2 in Python   \n","3  Databricks: How to Save Files in CSV on Your L...   \n","4  A Step-by-Step Implementation of Gradient Desc...   \n","\n","                                  subtitle   image  claps responses  \\\n","0                                      NaN   1.png    850         8   \n","1                                      NaN   2.png   1100        11   \n","2         A Grammar of Graphics for Python   3.png    767         1   \n","3  When I work on Python projects dealing…  4.jpeg    354         0   \n","4          One example of building neural…  5.jpeg    211         3   \n","\n","   reading_time           publication        date  \n","0             8  Towards Data Science  2019-05-30  \n","1             9  Towards Data Science  2019-05-30  \n","2             5  Towards Data Science  2019-05-30  \n","3             4  Towards Data Science  2019-05-30  \n","4             4  Towards Data Science  2019-05-30  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["medium_data = pd.read_csv('medium_data.csv')\n","medium_data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.605282Z","iopub.status.busy":"2023-12-03T19:01:29.604990Z","iopub.status.idle":"2023-12-03T19:01:29.610360Z","shell.execute_reply":"2023-12-03T19:01:29.609478Z","shell.execute_reply.started":"2023-12-03T19:01:29.605256Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of records:  6508\n","Number of fields:  10\n"]}],"source":["print(\"Number of records: \", medium_data.shape[0])\n","print(\"Number of fields: \", medium_data.shape[1])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.611638Z","iopub.status.busy":"2023-12-03T19:01:29.611398Z","iopub.status.idle":"2023-12-03T19:01:29.627949Z","shell.execute_reply":"2023-12-03T19:01:29.627020Z","shell.execute_reply.started":"2023-12-03T19:01:29.611616Z"},"trusted":true},"outputs":[],"source":["medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n","medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.631255Z","iopub.status.busy":"2023-12-03T19:01:29.630407Z","iopub.status.idle":"2023-12-03T19:01:29.847456Z","shell.execute_reply":"2023-12-03T19:01:29.846653Z","shell.execute_reply.started":"2023-12-03T19:01:29.631221Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.848802Z","iopub.status.busy":"2023-12-03T19:01:29.848509Z","iopub.status.idle":"2023-12-03T19:01:29.853002Z","shell.execute_reply":"2023-12-03T19:01:29.852102Z","shell.execute_reply.started":"2023-12-03T19:01:29.848776Z"},"trusted":true},"outputs":[],"source":["vocab_size = tokenizer.vocab_size"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.855100Z","iopub.status.busy":"2023-12-03T19:01:29.854354Z","iopub.status.idle":"2023-12-03T19:01:29.866282Z","shell.execute_reply":"2023-12-03T19:01:29.865426Z","shell.execute_reply.started":"2023-12-03T19:01:29.855065Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [101, 1037, 4088, 3678, 1521, 1055, 5009, 2000, 2773, 7861, 8270, 4667, 2007, 8991, 5332, 2213, 2773, 2475, 3726, 2278, 2944, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(medium_data.iloc[0]['title'])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:29.867701Z","iopub.status.busy":"2023-12-03T19:01:29.867394Z","iopub.status.idle":"2023-12-03T19:01:32.814617Z","shell.execute_reply":"2023-12-03T19:01:32.813730Z","shell.execute_reply.started":"2023-12-03T19:01:29.867677Z"},"trusted":true},"outputs":[],"source":["input_sequences = []\n","for line in medium_data['title']:\n","    token_list = tokenizer(line).input_ids\n","    #print(token_list)\n","    \n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:32.816107Z","iopub.status.busy":"2023-12-03T19:01:32.815803Z","iopub.status.idle":"2023-12-03T19:01:32.820889Z","shell.execute_reply":"2023-12-03T19:01:32.819985Z","shell.execute_reply.started":"2023-12-03T19:01:32.816081Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total input sequences:  79316\n"]}],"source":["print(\"Total input sequences: \", len(input_sequences))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:32.822783Z","iopub.status.busy":"2023-12-03T19:01:32.822174Z","iopub.status.idle":"2023-12-03T19:01:32.892448Z","shell.execute_reply":"2023-12-03T19:01:32.891644Z","shell.execute_reply.started":"2023-12-03T19:01:32.822751Z"},"trusted":true},"outputs":[],"source":["X = [lst[:-1] for lst in input_sequences]\n","Y = [lst[-1] for lst in input_sequences]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["max_length = max(map(len, X))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["X = [[0] * (max_length - len(lst)) + lst for lst in X]"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["X = torch.tensor(X, dtype=torch.long)  # Use torch.long if your data type is integer\n","Y = torch.tensor(Y, dtype=torch.long)  # Use torch.long if your data type is integer"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.515813Z","iopub.status.busy":"2023-12-03T19:01:34.515517Z","iopub.status.idle":"2023-12-03T19:01:34.526255Z","shell.execute_reply":"2023-12-03T19:01:34.525347Z","shell.execute_reply.started":"2023-12-03T19:01:34.515787Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([79316, 126])\n","torch.Size([79316])\n"]}],"source":["print(X.shape)\n","print(Y.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.540363Z","iopub.status.busy":"2023-12-03T19:01:34.539998Z","iopub.status.idle":"2023-12-03T19:01:34.554053Z","shell.execute_reply":"2023-12-03T19:01:34.553068Z","shell.execute_reply.started":"2023-12-03T19:01:34.540337Z"},"trusted":true},"outputs":[],"source":["class BiLSTMModel(pl.LightningModule):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(BiLSTMModel,self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx=0)\n","        self.bilstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, vocab_size)  # Multiply by 2 because of bidirectional\n","        self.dropout = nn.Dropout(0.4)\n","        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n","        self.val_accuracy = 0.0\n","        self.total_predictions = 0\n","        \n","\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        lstm_out, _ = self.bilstm(embedded)\n","        lstm_out = self.dropout(lstm_out)\n","        output = self.fc(lstm_out[:, -1, :])\n","        return output\n","    \n","    def training_step(self, batch, batch_idx) :\n","        x,label = batch\n","        output = self.forward(x)\n","        loss = self.criterion(output, label.argmax(dim=1))\n","        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx) :\n","        x,label = batch\n","        output = self.forward(x)\n","        loss = self.criterion(output, label.argmax(dim=1))\n","        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n","        \n","        # Get top-k predictions\n","        _, predicted_indices = output.topk(k=3, dim=1)\n","\n","        # Check if the correct label is in the top-k predictions\n","        self.val_accuracy += torch.any(predicted_indices == torch.argmax(label, dim=1, keepdim=True), dim=1).sum().item()\n","        self.total_predictions += label.size(0)\n","    \n","    def on_validation_epoch_end(self):\n","        accuracy = self.val_accuracy / self.total_predictions\n","        self.log('val_accuracy', accuracy, on_step=False, on_epoch=True, prog_bar=True)\n","\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=0.001)\n","        \n","    "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.555621Z","iopub.status.busy":"2023-12-03T19:01:34.555284Z","iopub.status.idle":"2023-12-03T19:01:34.567788Z","shell.execute_reply":"2023-12-03T19:01:34.566897Z","shell.execute_reply.started":"2023-12-03T19:01:34.555590Z"},"trusted":true},"outputs":[],"source":["# Define a custom dataset\n","class SequenceDataset(Dataset):\n","    def __init__(self, input_sequences, target_sequences):\n","        self.input_sequences = input_sequences\n","        self.target_sequences = target_sequences\n","\n","    def __len__(self):\n","        return len(self.input_sequences)\n","\n","    def __getitem__(self, idx):\n","        ys = F.one_hot(self.target_sequences[idx], num_classes=vocab_size)\n","\n","        return self.input_sequences[idx], ys\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.569518Z","iopub.status.busy":"2023-12-03T19:01:34.568977Z","iopub.status.idle":"2023-12-03T19:01:34.583195Z","shell.execute_reply":"2023-12-03T19:01:34.582226Z","shell.execute_reply.started":"2023-12-03T19:01:34.569482Z"},"trusted":true},"outputs":[],"source":["class SequenceDataModule(pl.LightningDataModule):\n","    def __init__(self, input_sequences, target_sequences, batch_size=32):\n","        super(SequenceDataModule, self).__init__()\n","        self.input_sequences = input_sequences\n","        self.target_sequences = target_sequences\n","        self.batch_size = batch_size\n","\n","    def setup(self, stage=None):\n","        # Split dataset into training and validation sets\n","        total_samples = len(self.input_sequences)\n","        val_samples = int(0.2 * total_samples)  # Adjust the validation split as needed\n","        train_samples = total_samples - val_samples\n","\n","        self.train_dataset, self.val_dataset = random_split(\n","            dataset=SequenceDataset(self.input_sequences, self.target_sequences),\n","            lengths=[train_samples, val_samples],\n","            generator=torch.Generator().manual_seed(42)  # Set seed for reproducibility\n","        )\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=3,shuffle=True)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.val_dataset, num_workers=3,batch_size=self.batch_size)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.585441Z","iopub.status.busy":"2023-12-03T19:01:34.584554Z","iopub.status.idle":"2023-12-03T19:01:34.593317Z","shell.execute_reply":"2023-12-03T19:01:34.592557Z","shell.execute_reply.started":"2023-12-03T19:01:34.585412Z"},"trusted":true},"outputs":[],"source":["epochs = 50\n","batch_size = 256"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.594714Z","iopub.status.busy":"2023-12-03T19:01:34.594397Z","iopub.status.idle":"2023-12-03T19:01:34.609648Z","shell.execute_reply":"2023-12-03T19:01:34.608804Z","shell.execute_reply.started":"2023-12-03T19:01:34.594690Z"},"trusted":true},"outputs":[],"source":["# Instantiate your SequenceDataModule\n","data_module = SequenceDataModule(X, Y, batch_size=batch_size)\n","\n","data_module.setup()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.611158Z","iopub.status.busy":"2023-12-03T19:01:34.610831Z","iopub.status.idle":"2023-12-03T19:01:34.616326Z","shell.execute_reply":"2023-12-03T19:01:34.615358Z","shell.execute_reply.started":"2023-12-03T19:01:34.611133Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset Length: 63453\n","Val Dataset Length: 15863\n"]}],"source":["# Optionally, inspect the datasets and dataloaders\n","print(\"Train Dataset Length:\", len(data_module.train_dataset))\n","print(\"Val Dataset Length:\", len(data_module.val_dataset))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.617830Z","iopub.status.busy":"2023-12-03T19:01:34.617512Z","iopub.status.idle":"2023-12-03T19:01:34.754929Z","shell.execute_reply":"2023-12-03T19:01:34.753911Z","shell.execute_reply.started":"2023-12-03T19:01:34.617794Z"},"trusted":true},"outputs":[],"source":["model = BiLSTMModel(vocab_size, 256, 128)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.756598Z","iopub.status.busy":"2023-12-03T19:01:34.756238Z","iopub.status.idle":"2023-12-03T19:01:34.764809Z","shell.execute_reply":"2023-12-03T19:01:34.763826Z","shell.execute_reply.started":"2023-12-03T19:01:34.756566Z"},"trusted":true},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","    dirpath = 'checkpoints',\n","    filename = 'BestNWP',\n","    save_top_k = 1,\n","    verbose = True,\n","    monitor = 'val_loss',\n","    mode = 'min'\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.766186Z","iopub.status.busy":"2023-12-03T19:01:34.765921Z","iopub.status.idle":"2023-12-03T19:01:34.826652Z","shell.execute_reply":"2023-12-03T19:01:34.825882Z","shell.execute_reply.started":"2023-12-03T19:01:34.766163Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]}],"source":["trainer = pl.Trainer(devices=-1, \n","                  accelerator=\"gpu\",\n","                  check_val_every_n_epoch=5,\n","                  max_epochs=epochs)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T19:01:34.828671Z","iopub.status.busy":"2023-12-03T19:01:34.828164Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | embedding | Embedding        | 7.8 M \n","1 | bilstm    | LSTM             | 395 K \n","2 | fc        | Linear           | 7.8 M \n","3 | dropout   | Dropout          | 0     \n","4 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","16.1 M    Trainable params\n","0         Non-trainable params\n","16.1 M    Total params\n","64.212    Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15:  58%|█████▊    | 145/248 [00:16<00:11,  8.73it/s, loss=2.75, v_num=3, train_loss_step=2.970, train_loss_epoch=2.770, val_loss_step=5.050, val_loss_epoch=5.390, val_accuracy=0.392]"]},{"name":"stderr","output_type":"stream","text":["/home/sushovan/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["trainer.fit(model=model,datamodule=data_module)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["def predict(seed_text,next_words=3):\n","    \n","    print(\"Actual : \",seed_text)\n","\n","    # Generate next words\n","    for _ in range(next_words):\n","        # Tokenize seed_text\n","        token_list = tokenizer(seed_text,)['input_ids']\n","        \n","        token_list = [0] * (max_length - len(token_list)) + token_list\n","        \n","        token_list = torch.tensor(token_list, dtype=torch.long).unsqueeze(0)  # Use torch.long if your data type is integer\n","                \n","        # Move token_list to GPU if available\n","        token_list = token_list.to(device)\n","        with torch.no_grad():\n","            output = model(token_list)\n","            \n","        # Get the index of the predicted word\n","        predicted_index = torch.argmax(output, dim=-1)\n","        \n","        # Convert index to word\n","        output_word = tokenizer.decode(predicted_index)\n","\n","        # Update the seed_text\n","        seed_text += \" \" + output_word\n","        \n","    print(\"Predict : \",seed_text)"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["seed_text = \"What if AI model\""]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual :  What if AI model\n","Predict :  What if AI model in a ##or ?\n"]}],"source":["# Print the generated text\n","predict(seed_text,next_words=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":748442,"sourceId":1294572,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
