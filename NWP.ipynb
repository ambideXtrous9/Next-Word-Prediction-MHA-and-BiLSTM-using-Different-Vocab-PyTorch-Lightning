{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushovan/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>image</th>\n",
       "      <th>claps</th>\n",
       "      <th>responses</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>publication</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.png</td>\n",
       "      <td>850</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.png</td>\n",
       "      <td>1100</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>A Grammar of Graphics for Python</td>\n",
       "      <td>3.png</td>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/databricks-how-...</td>\n",
       "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
       "      <td>When I work on Python projects dealing…</td>\n",
       "      <td>4.jpeg</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>One example of building neural…</td>\n",
       "      <td>5.jpeg</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                url  \\\n",
       "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
       "1   2  https://towardsdatascience.com/hands-on-graph-...   \n",
       "2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n",
       "3   4  https://towardsdatascience.com/databricks-how-...   \n",
       "4   5  https://towardsdatascience.com/a-step-by-step-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Files in CSV on Your L...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                  subtitle   image  claps responses  \\\n",
       "0                                      NaN   1.png    850         8   \n",
       "1                                      NaN   2.png   1100        11   \n",
       "2         A Grammar of Graphics for Python   3.png    767         1   \n",
       "3  When I work on Python projects dealing…  4.jpeg    354         0   \n",
       "4          One example of building neural…  5.jpeg    211         3   \n",
       "\n",
       "   reading_time           publication        date  \n",
       "0             8  Towards Data Science  2019-05-30  \n",
       "1             9  Towards Data Science  2019-05-30  \n",
       "2             5  Towards Data Science  2019-05-30  \n",
       "3             4  Towards Data Science  2019-05-30  \n",
       "4             4  Towards Data Science  2019-05-30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data = pd.read_csv('medium_data.csv')\n",
    "medium_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  6508\n",
      "Number of fields:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records: \", medium_data.shape[0])\n",
    "print(\"Number of fields: \", medium_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize a BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1037, 4088, 3678, 1521, 1055, 5009, 2000, 2773, 7861, 8270, 4667, 2007, 8991, 5332, 2213, 2773, 2475, 3726, 2278, 2944, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(medium_data.iloc[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in medium_data['title']:\n",
    "    token_list = tokenizer(line).input_ids\n",
    "    #print(token_list)\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences:  79316\n"
     ]
    }
   ],
   "source": [
    "# print(input_sequences)\n",
    "print(\"Total input sequences: \", len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [lst[:-1] for lst in input_sequences]\n",
    "Y = [lst[-1] for lst in input_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(map(len, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0] * (max_length - len(lst)) + lst for lst in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.long)  # Use torch.long if your data type is integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor(Y, dtype=torch.long)  # Use torch.long if your data type is integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79316, 126])\n",
      "torch.Size([79316])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BiLSTM model\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_size, \n",
    "                              num_layers=3,\n",
    "                              dropout=0.2,\n",
    "                              batch_first=True, \n",
    "                              bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, vocab_size)  # Multiply by 2 because of bidirectional\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embedded)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTMModel(vocab_size, 256, 128).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, input_sequences, target_sequences):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.target_sequences = target_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ys = F.one_hot(self.target_sequences[idx], num_classes=vocab_size)\n",
    "\n",
    "        return self.input_sequences[idx], ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.30it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 6.8051, Accuracy: 16.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.22it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 5.8152, Accuracy: 27.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     3.91it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 5.4745, Accuracy: 30.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.19it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 5.2297, Accuracy: 32.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.72it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 5.0149, Accuracy: 34.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     3.91it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 4.8216, Accuracy: 36.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.44it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 4.6386, Accuracy: 38.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.09it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 4.4605, Accuracy: 39.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     4.14it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 4.3002, Accuracy: 41.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 4.1413, Accuracy: 42.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Training loop with DataLoader\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    tqdm_dataloader = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", \n",
    "                           leave=False,\n",
    "                           bar_format='{desc}: {percentage:3.0f}%|{bar:50}{r_bar}',\n",
    "                           colour='green')\n",
    "\n",
    "    for input_batch, target_batch in tqdm_dataloader:\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_batch)\n",
    "        loss = criterion(outputs, target_batch.argmax(dim=1))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        _, predicted_indices = outputs.topk(k=3, dim=1)\n",
    "\n",
    "        # Check if the correct label is in the top-k predictions\n",
    "        correct_predictions += torch.any(predicted_indices == torch.argmax(target_batch, dim=1, keepdim=True), dim=1).sum().item()\n",
    "        total_samples += target_batch.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(seed_text,next_words=3):\n",
    "    \n",
    "    print(\"Actual : \",seed_text)\n",
    "\n",
    "    # Generate next words\n",
    "    for _ in range(next_words):\n",
    "        # Tokenize seed_text\n",
    "        token_list = tokenizer(seed_text,)['input_ids']\n",
    "        \n",
    "        token_list = [0] * (max_length - len(token_list)) + token_list\n",
    "        \n",
    "        token_list = torch.tensor(token_list, dtype=torch.long).unsqueeze(0)  # Use torch.long if your data type is integer\n",
    "                \n",
    "        \n",
    "        # Move token_list to GPU if available\n",
    "        token_list = token_list.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(token_list)\n",
    "            \n",
    "\n",
    "        # Get the index of the predicted word\n",
    "        predicted_index = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        \n",
    "        # Convert index to word\n",
    "        output_word = tokenizer.decode(predicted_index)\n",
    "\n",
    "        # Update the seed_text\n",
    "        seed_text += \" \" + output_word\n",
    "        \n",
    "    print(\"Predict : \",seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How To Limit Your Exposure To The Surveillance Capitalism\n"
     ]
    }
   ],
   "source": [
    "print(medium_data.iloc[78]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example seed_text\n",
    "seed_text = \"How To Limit Your Exposure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual :  How To Limit Your Exposure\n",
      "Predict :  How To Limit Your Exposure in [SEP] [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Print the generated text\n",
    "predict(seed_text,next_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
